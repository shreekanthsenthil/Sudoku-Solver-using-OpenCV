{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "import numpy\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape to be samples*pixels*width*height\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1).astype('float32')\n",
    "\n",
    "# Normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# One Hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3523 - accuracy: 0.8926 - val_loss: 0.0772 - val_accuracy: 0.9752\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0933 - accuracy: 0.9709 - val_loss: 0.0520 - val_accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0677 - accuracy: 0.9791 - val_loss: 0.0355 - val_accuracy: 0.9878\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0557 - accuracy: 0.9822 - val_loss: 0.0331 - val_accuracy: 0.9889\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0464 - accuracy: 0.9857 - val_loss: 0.0297 - val_accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 0.0274 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.0298 - val_accuracy: 0.9905\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0258 - val_accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0256 - val_accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0259 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f98f01c6fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "\n",
    "# Final evaluation of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large CNN Error: 0.88%\n",
      "Prediction of model: 2\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "#  - - - - - - - TEST single image - - - - - - - -\n",
    "\n",
    "image = (X_test[1]).reshape(1,28,28,1) # 1->'2';    \n",
    "model_pred = model.predict_classes(image, verbose = 0)\n",
    "print('Prediction of model: {}'.format(model_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - TESTING multiple image - - - - - - - - - -\n",
    "\n",
    "test_images = X_test[1:5]\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28,1)\n",
    "print (\"Test images shape: {}\".format(test_images.shape))\n",
    "\n",
    "for i, test_image in enumerate(test_images, start=1):\n",
    "    org_image = test_image\n",
    "    test_image = test_image.reshape(1,28,28,1)\n",
    "    prediction = model.predict_classes(test_image, verbose=0)\n",
    "\n",
    "    print (\"Predicted digit: {}\".format(prediction[0]))\n",
    "    plt.subplot(220+i)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Predicted digit: {}\".format(prediction[0]))\n",
    "    plt.imshow(org_image, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# - - - - - - - SAVE THE MODEL - - - - - - - -\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
